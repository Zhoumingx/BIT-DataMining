import os
import pandas as pd
import re
import time

def is_all_chinese(text):
    return isinstance(text, str) and all('\u4e00' <= ch <= '\u9fff' for ch in text)

def is_valid_email(email):
    return isinstance(email, str) and bool(re.match(r"[^@]+@[^@]+\.[^@]+", email))

def is_valid_username(username):
    return isinstance(username, str) and bool(re.match(r"^[A-Za-z0-9_]+$", username))

def load_dataset(folder_path):
    all_dfs = []
    for fname in os.listdir(folder_path):
        if fname.endswith('.parquet'):
            file_path = os.path.join(folder_path, fname)
            try:
                df = pd.read_parquet(file_path)
                all_dfs.append(df)
            except Exception as e:
                print(f"âŒ Error reading {fname}: {e}")
    if all_dfs:
        return pd.concat(all_dfs, ignore_index=True)
    else:
        print(f"âš ï¸ No valid parquet files found in {folder_path}")
        return pd.DataFrame()

def check_id_unique_in_parquet(folder_path):
    results = []
    for fname in os.listdir(folder_path):
        if fname.endswith('.parquet'):
            file_path = os.path.join(folder_path, fname)
            try:
                df = pd.read_parquet(file_path)
                is_int = pd.api.types.is_integer_dtype(df['id'])
                is_unique = df['id'].is_unique
                results.append((fname, is_int, is_unique))
            except Exception as e:
                results.append((fname, False, False))
    return results

def data_quality_check(df, dataset_name):
    report = {}

    # å­—æ®µå­˜åœ¨æ€§æ£€æŸ¥
    report['missing_values'] = df.isnull().sum()

    # user_name åˆæ³•æ€§
    report['invalid_user_name'] = df[~df['user_name'].apply(is_valid_username)].shape[0]

    # fullname åˆæ³•æ€§ï¼ˆä¸­æ–‡ï¼‰
    report['invalid_fullname'] = df[~df['fullname'].apply(is_all_chinese)].shape[0]

    # email åˆæ³•æ€§
    report['invalid_email'] = df[~df['email'].apply(is_valid_email)].shape[0]

    # æ±‡æ€»æ‰“å°
    print(f"\nğŸ“‹ æ•°æ®é›†ã€{dataset_name}ã€‘å­—æ®µåˆæ³•æ€§æ£€æŸ¥ï¼š")
    print("ç¼ºå¤±å€¼ç»Ÿè®¡ï¼š")
    print(report['missing_values'])
    print(f"user_name éæ³•æ•°é‡ï¼š{report['invalid_user_name']}")
    print(f"fullname éä¸­æ–‡æ•°é‡ï¼š{report['invalid_fullname']}")
    print(f"email éæ³•æ•°é‡ï¼š{report['invalid_email']}")

    return report

def check_dataset_quality(folder_path, df, name):
    # æ£€æŸ¥ id åœ¨æ¯ä¸ª parquet æ–‡ä»¶ä¸­æ˜¯å¦å”¯ä¸€
    id_check = check_id_unique_in_parquet(folder_path)
    print(f"\nğŸ“‚ æ•°æ®é›†ã€{name}ã€‘çš„æ¯ä¸ª parquet æ–‡ä»¶ä¸­ id å”¯ä¸€æ€§æ£€æŸ¥ï¼š")
    for fname, is_int, is_unique in id_check:
        print(f"{fname} - id ç±»å‹æ•´æ•°: {is_int}ï¼Œå”¯ä¸€æ€§: {is_unique}")

    # å…¶ä»–å­—æ®µæ£€æŸ¥
    _ = data_quality_check(df, dataset_name=name)

def filter_gender_other(df, dataset_name):
    total = len(df)
    gender_other_count = df[df['gender'] == 'å…¶ä»–'].shape[0]
    gender_other_ratio = gender_other_count / total if total > 0 else 0

    print(f"\nğŸ“Š æ•°æ®é›†ã€{dataset_name}ã€‘åˆ é™¤å‰æ€»è®°å½•æ•°: {total}")
    print(f"ğŸ” 'gender' ä¸º 'å…¶ä»–' çš„è®°å½•æ•°: {gender_other_count}ï¼Œå æ¯”: {gender_other_ratio:.2%}")

    # åˆ é™¤ gender ä¸º "å…¶ä»–" çš„è¡Œ
    df_filtered = df[df['gender'] != 'å…¶ä»–']
    new_total = len(df_filtered)

    print(f"ğŸ§¹ åˆ é™¤åè®°å½•æ•°: {new_total}ï¼Œå‡å°‘äº†: {total - new_total} æ¡\n")

    return df_filtered

path_10g = './10G_data_new'
path_30g = './30G_data_new'

df_10g = load_dataset(path_10g)
df_30g = load_dataset(path_30g)

start_10g = time.time()
check_dataset_quality(path_10g, df_10g, name='10G')
vis_time_10g = time.time() - start_10g
print(f"10G æ•°æ®è´¨é‡æ£€æµ‹è€—æ—¶ï¼š{vis_time_10g:.2f} ç§’")

start_30g = time.time()
check_dataset_quality(path_30g, df_30g, name='30G')
vis_time_30g = time.time() - start_30g
print(f"30G æ•°æ®è´¨é‡æ£€æµ‹è€—æ—¶ï¼š{vis_time_30g:.2f} ç§’")