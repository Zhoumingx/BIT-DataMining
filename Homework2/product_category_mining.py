import pandas as pd
import os
import json
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder

# è®¾ç½®è·¯å¾„
parquet_dir = './30G_data'
product_catalog_path = './product_catalog.json'

# åŠ è½½å•†å“ç›®å½•
with open(product_catalog_path, 'r', encoding='utf-8') as f:
    product_catalog = json.load(f)
product_map = {item['id']: item['category'] for item in product_catalog['products']}

# å®šä¹‰å•†å“å­ç±»åˆ«ä¸å…¶æ‰€å±å¤§ç±»çš„æ˜ å°„
category_to_group = {
    # ç”µå­äº§å“
    'æ™ºèƒ½æ‰‹æœº': 'ç”µå­äº§å“', 'ç¬”è®°æœ¬ç”µè„‘': 'ç”µå­äº§å“', 'å¹³æ¿ç”µè„‘': 'ç”µå­äº§å“',
    'æ™ºèƒ½æ‰‹è¡¨': 'ç”µå­äº§å“', 'è€³æœº': 'ç”µå­äº§å“', 'éŸ³å“': 'ç”µå­äº§å“',
    'ç›¸æœº': 'ç”µå­äº§å“', 'æ‘„åƒæœº': 'ç”µå­äº§å“', 'æ¸¸æˆæœº': 'ç”µå­äº§å“',

    # æœè£…
    'ä¸Šè¡£': 'æœè£…', 'è£¤å­': 'æœè£…', 'è£™å­': 'æœè£…', 'å†…è¡£': 'æœè£…',
    'é‹å­': 'æœè£…', 'å¸½å­': 'æœè£…', 'æ‰‹å¥—': 'æœè£…', 'å›´å·¾': 'æœè£…', 'å¤–å¥—': 'æœè£…',

    # é£Ÿå“
    'é›¶é£Ÿ': 'é£Ÿå“', 'é¥®æ–™': 'é£Ÿå“', 'è°ƒå‘³å“': 'é£Ÿå“', 'ç±³é¢': 'é£Ÿå“',
    'æ°´äº§': 'é£Ÿå“', 'è‚‰ç±»': 'é£Ÿå“', 'è›‹å¥¶': 'é£Ÿå“', 'æ°´æœ': 'é£Ÿå“', 'è”¬èœ': 'é£Ÿå“',

    # å®¶å±…
    'å®¶å…·': 'å®¶å±…', 'åºŠä¸Šç”¨å“': 'å®¶å±…', 'å¨å…·': 'å®¶å±…', 'å«æµ´ç”¨å“': 'å®¶å±…',

    # åŠå…¬
    'æ–‡å…·': 'åŠå…¬', 'åŠå…¬ç”¨å“': 'åŠå…¬',

    # è¿åŠ¨æˆ·å¤–
    'å¥èº«å™¨æ': 'è¿åŠ¨æˆ·å¤–', 'æˆ·å¤–è£…å¤‡': 'è¿åŠ¨æˆ·å¤–',

    # ç©å…·
    'ç©å…·': 'ç©å…·', 'æ¨¡å‹': 'ç©å…·', 'ç›Šæ™ºç©å…·': 'ç©å…·',

    # æ¯å©´
    'å©´å„¿ç”¨å“': 'æ¯å©´', 'å„¿ç«¥è¯¾å¤–è¯»ç‰©': 'æ¯å©´',

    # æ±½è½¦ç”¨å“
    'è½¦è½½ç”µå­': 'æ±½è½¦ç”¨å“', 'æ±½è½¦è£…é¥°': 'æ±½è½¦ç”¨å“'
}


# æ”¶é›†æ‰€æœ‰è®¢å•çš„å¤§ç±»ç»„åˆ
transactions = []

for file in sorted(os.listdir(parquet_dir)):
    if file.endswith('.parquet') and file.startswith('part-'):
        df = pd.read_parquet(os.path.join(parquet_dir, file), engine='pyarrow')
        for record in df['purchase_history'].dropna():
            try:
                history = json.loads(record) if isinstance(record, str) else record
                item_ids = [item['id'] for item in history.get('items', [])]
                # è·å–å¤§ç±»ï¼ˆå»é‡ï¼‰
                major_groups = list(set(
                    category_to_group.get(product_map.get(item_id)) 
                    for item_id in item_ids 
                    if item_id in product_map and product_map.get(item_id) in category_to_group
                ))
                if major_groups:
                    transactions.append(major_groups)
            except Exception as e:
                continue

# è½¬æ¢ä¸º one-hot ç¼–ç 
te = TransactionEncoder()
te_array = te.fit(transactions).transform(transactions)
df_encoded = pd.DataFrame(te_array, columns=te.columns_)

# é¢‘ç¹é¡¹é›†
frequent_itemsets = apriori(df_encoded, min_support=0.02, use_colnames=True)

# ç”Ÿæˆå…³è”è§„åˆ™
rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.4)
rules['antecedents'] = rules['antecedents'].apply(set)
rules['consequents'] = rules['consequents'].apply(set)

# ç”µå­äº§å“ç›¸å…³
is_electronics = lambda row: 'ç”µå­äº§å“' in row['antecedents'] or 'ç”µå­äº§å“' in row['consequents']
electronics_rules = rules[rules.apply(is_electronics, axis=1)].sort_values(by='support', ascending=False).head(10)

# éç”µå­äº§å“é—´å…¸å‹å…³è”ï¼ˆæ’é™¤ç”µå­äº§å“ï¼‰
other_rules = rules[~rules.apply(is_electronics, axis=1)].sort_values(by='support', ascending=False).head(10)

# åˆå¹¶ç»“æœï¼ˆéƒ¨åˆ†å±•ç¤ºï¼‰
combined_rules = pd.concat([electronics_rules, other_rules])
combined_rules_display = combined_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]

# æ‰“å°ç»ˆç«¯è¾“å‡º
print("\nğŸ“Š ç”µå­äº§å“ç›¸å…³ & éç”µå­äº§å“éƒ¨åˆ†å…³è”è§„åˆ™ï¼ˆå‰10æ¡ï¼‰ï¼š\n")
print(combined_rules_display.to_string(index=False))

